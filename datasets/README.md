# Datasets

Structured data supporting analysis lives here. See [LinkedIn](../LinkedIn/) and [case-studies](../case-studies/) for examples of how these datasets support those analyses.

## Standard Schema
Most CSV and JSON datasets use the following fields:

- `profile_id`: Unique identifier for a profile or record.
- `sector`: Industry or target sector linked to the entry.
- `source`: Origin of the data (e.g., OSINT, report, internal).

CSV files require a header row; JSON files should be arrays of objects with these keys. Some
specialized datasets define alternate schemas, which are documented in their file descriptions
below.

### MCF Institution Partnerships Schema
`mcf_institution_partnerships.csv` tracks academic collaborations with Chinese institutions and
uses the following fields:

- `institution`: Non-Chinese organization involved in the partnership.
- `partner`: Chinese institution in the collaboration.
- `relationship_type`: Nature of the partnership (e.g., joint institute, academic center).
- `source`: Reference supporting the relationship.

### Additional Schemas
Some datasets may deviate from the standard schema. For example,
`mcf_institution_partnerships.csv` tracks Military‑Civil Fusion partnerships
using the columns:

- `institution`
- `partner`
- `relationship_type`
- `source`

## Maintaining Data
- Append records with `python` [`update_datasets.py`](../scripts/update_datasets.py)
  and the appropriate subcommand:
  - `profile <file> <profile_id> <sector> <source>` for standard datasets.
  - `partnership <file> <institution> <partner> <relationship_type> <source>`
    for `mcf_institution_partnerships.csv`.
- Generate summary statistics via `python`
  [`analyze_datasets.py`](../scripts/analyze_datasets.py), which updates
  `analysis_summary.md`.
- Validation tests for these scripts live under [`../tests/`](../tests/).

### Walkthrough: Running Dataset Analysis
1. From the repository root, execute:

   ```bash
   python scripts/analyze_datasets.py
   ```

2. The script scans every CSV in `datasets/` and writes counts to
   `analysis_summary.md`.

3. Review the generated summary for totals and category breakdowns, for
   example:

   ```markdown
   ## fake_profiles.csv
   - Total records: 2
   - energy: 1
   - technology: 1
   ```

   Each section lists the dataset name, total records, and counts by
   `sector` or `institution`.

## Current Files
- [`fake_profiles.csv`](fake_profiles.csv) – suspected synthetic or compromised LinkedIn profiles. See [`fake_profiles.md`](fake_profiles.md).
- [`indictments.csv`](indictments.csv) – legal indictment information tied to MSS activities. See [`indictments.md`](indictments.md).
- [`mcf_institution_partnerships.csv`](mcf_institution_partnerships.csv) – academic partnerships involving Chinese institutions. Fields: `institution`, `partner`, `relationship_type`, `source`. See [`mcf_institution_partnerships.md`](mcf_institution_partnerships.md).
- [`analysis_summary.md`](analysis_summary.md) – autogenerated counts by sector for each dataset.

## Future Data Needs
- Include image hashes and message metadata for each profile.
- Track cross-platform links and infrastructure identifiers.

Use these datasets responsibly; entries may contain unverified or sensitive information.
